\relax 
\abx@aux@refcontext{none/global//global/global}
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\abx@aux@cite{0}{attenion_is_all_you_need}
\abx@aux@segm{0}{0}{attenion_is_all_you_need}
\abx@aux@cite{0}{mattersim}
\abx@aux@segm{0}{0}{mattersim}
\abx@aux@cite{0}{pmlr-v155-anderson21a}
\abx@aux@segm{0}{0}{pmlr-v155-anderson21a}
\abx@aux@cite{0}{krantz2020navgraphvisionandlanguagenavigationcontinuous}
\abx@aux@segm{0}{0}{krantz2020navgraphvisionandlanguagenavigationcontinuous}
\abx@aux@cite{0}{long2023_discussnav}
\abx@aux@segm{0}{0}{long2023_discussnav}
\abx@aux@cite{0}{pan2024langnavlanguageperceptualrepresentation}
\abx@aux@segm{0}{0}{pan2024langnavlanguageperceptualrepresentation}
\abx@aux@cite{0}{zhou2023navgptexplicitreasoningvisionandlanguage}
\abx@aux@segm{0}{0}{zhou2023navgptexplicitreasoningvisionandlanguage}
\abx@aux@cite{0}{lin2024navcotboostingllmbasedvisionandlanguage}
\abx@aux@segm{0}{0}{lin2024navcotboostingllmbasedvisionandlanguage}
\abx@aux@cite{0}{open-nav}
\abx@aux@segm{0}{0}{open-nav}
\abx@aux@cite{0}{openai2024gpt4technicalreport}
\abx@aux@segm{0}{0}{openai2024gpt4technicalreport}
\abx@aux@cite{0}{li2022blipbootstrappinglanguageimagepretraining}
\abx@aux@segm{0}{0}{li2022blipbootstrappinglanguageimagepretraining}
\abx@aux@cite{0}{pan2024langnavlanguageperceptualrepresentation}
\abx@aux@segm{0}{0}{pan2024langnavlanguageperceptualrepresentation}
\abx@aux@cite{0}{hong2021_vlnbert}
\abx@aux@segm{0}{0}{hong2021_vlnbert}
\abx@aux@cite{0}{navgpt2}
\abx@aux@segm{0}{0}{navgpt2}
\abx@aux@cite{0}{chen2021_HAMT}
\abx@aux@segm{0}{0}{chen2021_HAMT}
\abx@aux@cite{0}{HE2024110511_MemoryAdaptiveVLN}
\abx@aux@segm{0}{0}{HE2024110511_MemoryAdaptiveVLN}
\abx@aux@cite{0}{Qwen-VL}
\abx@aux@segm{0}{0}{Qwen-VL}
\abx@aux@cite{0}{Qwen2VL}
\abx@aux@segm{0}{0}{Qwen2VL}
\abx@aux@cite{0}{qwen2}
\abx@aux@segm{0}{0}{qwen2}
\abx@aux@cite{0}{geminiteam2024geminifamilyhighlycapable}
\abx@aux@segm{0}{0}{geminiteam2024geminifamilyhighlycapable}
\abx@aux@cite{0}{openai2024gpt4technicalreport}
\abx@aux@segm{0}{0}{openai2024gpt4technicalreport}
\abx@aux@cite{0}{LoRA}
\abx@aux@segm{0}{0}{LoRA}
\abx@aux@cite{0}{MLSYS2024_42a452cb}
\abx@aux@segm{0}{0}{MLSYS2024_42a452cb}
\@writefile{toc}{\contentsline {title}{Exploring a Small Vision Language Model Approach for Vision and Language Navigation Tasks in Continuous Environments}{2}{chapter.1}\protected@file@percent }
\@writefile{toc}{\authcount {1}}
\@writefile{toc}{\contentsline {author}{Wesley Chiu, Abdulrahman Altahhan}{2}{chapter.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{2}{section.1.1}\protected@file@percent }
\abx@aux@cite{0}{8578485}
\abx@aux@segm{0}{0}{8578485}
\abx@aux@cite{0}{8578485}
\abx@aux@segm{0}{0}{8578485}
\abx@aux@cite{0}{8954045}
\abx@aux@segm{0}{0}{8954045}
\abx@aux@cite{0}{8953608}
\abx@aux@segm{0}{0}{8953608}
\abx@aux@cite{0}{li2019robustnavigationlanguagepretraining}
\abx@aux@segm{0}{0}{li2019robustnavigationlanguagepretraining}
\abx@aux@cite{0}{attenion_is_all_you_need}
\abx@aux@segm{0}{0}{attenion_is_all_you_need}
\abx@aux@cite{0}{radford2018improving}
\abx@aux@segm{0}{0}{radford2018improving}
\abx@aux@cite{0}{touvron2023llamaopenefficientfoundation}
\abx@aux@segm{0}{0}{touvron2023llamaopenefficientfoundation}
\abx@aux@cite{0}{pan2024langnavlanguageperceptualrepresentation}
\abx@aux@segm{0}{0}{pan2024langnavlanguageperceptualrepresentation}
\abx@aux@cite{0}{zhou2023navgptexplicitreasoningvisionandlanguage}
\abx@aux@segm{0}{0}{zhou2023navgptexplicitreasoningvisionandlanguage}
\abx@aux@cite{0}{li2022blipbootstrappinglanguageimagepretraining}
\abx@aux@segm{0}{0}{li2022blipbootstrappinglanguageimagepretraining}
\abx@aux@cite{0}{li2023blip2bootstrappinglanguageimagepretraining}
\abx@aux@segm{0}{0}{li2023blip2bootstrappinglanguageimagepretraining}
\abx@aux@cite{0}{zhu2021deformabledetrdeformabletransformers}
\abx@aux@segm{0}{0}{zhu2021deformabledetrdeformabletransformers}
\abx@aux@cite{0}{open-nav}
\abx@aux@segm{0}{0}{open-nav}
\abx@aux@cite{0}{long2023_discussnav}
\abx@aux@segm{0}{0}{long2023_discussnav}
\abx@aux@cite{0}{lin2024navcotboostingllmbasedvisionandlanguage}
\abx@aux@segm{0}{0}{lin2024navcotboostingllmbasedvisionandlanguage}
\abx@aux@cite{0}{dosovitskiy2021imageworth16x16words}
\abx@aux@segm{0}{0}{dosovitskiy2021imageworth16x16words}
\abx@aux@cite{0}{pan2024langnavlanguageperceptualrepresentation}
\abx@aux@segm{0}{0}{pan2024langnavlanguageperceptualrepresentation}
\abx@aux@cite{0}{9156554}
\abx@aux@segm{0}{0}{9156554}
\abx@aux@cite{0}{krantz2020navgraphvisionandlanguagenavigationcontinuous}
\abx@aux@segm{0}{0}{krantz2020navgraphvisionandlanguagenavigationcontinuous}
\abx@aux@cite{0}{Guhur_2021_ICCV}
\abx@aux@segm{0}{0}{Guhur_2021_ICCV}
\abx@aux@cite{0}{chen2021_HAMT}
\abx@aux@segm{0}{0}{chen2021_HAMT}
\abx@aux@cite{0}{devlin-etal-2019-bert}
\abx@aux@segm{0}{0}{devlin-etal-2019-bert}
\abx@aux@cite{0}{dosovitskiy2021imageworth16x16words}
\abx@aux@segm{0}{0}{dosovitskiy2021imageworth16x16words}
\abx@aux@cite{0}{navgpt2}
\abx@aux@segm{0}{0}{navgpt2}
\abx@aux@cite{0}{dai2023instructblipgeneralpurposevisionlanguagemodels}
\abx@aux@segm{0}{0}{dai2023instructblipgeneralpurposevisionlanguagemodels}
\abx@aux@cite{0}{10203681}
\abx@aux@segm{0}{0}{10203681}
\abx@aux@cite{0}{51647}
\abx@aux@segm{0}{0}{51647}
\abx@aux@cite{0}{wu2022visionlanguagenavigationsurveytaxonomy}
\abx@aux@segm{0}{0}{wu2022visionlanguagenavigationsurveytaxonomy}
\abx@aux@cite{0}{pan2024langnavlanguageperceptualrepresentation}
\abx@aux@segm{0}{0}{pan2024langnavlanguageperceptualrepresentation}
\abx@aux@cite{0}{zhou2023navgptexplicitreasoningvisionandlanguage}
\abx@aux@segm{0}{0}{zhou2023navgptexplicitreasoningvisionandlanguage}
\abx@aux@cite{0}{chen2021_HAMT}
\abx@aux@segm{0}{0}{chen2021_HAMT}
\abx@aux@cite{0}{HE2024110511_MemoryAdaptiveVLN}
\abx@aux@segm{0}{0}{HE2024110511_MemoryAdaptiveVLN}
\abx@aux@cite{0}{9879544}
\abx@aux@segm{0}{0}{9879544}
\abx@aux@cite{0}{chen-etal-2024-mapgpt}
\abx@aux@segm{0}{0}{chen-etal-2024-mapgpt}
\abx@aux@cite{0}{dai2023instructblipgeneralpurposevisionlanguagemodels}
\abx@aux@segm{0}{0}{dai2023instructblipgeneralpurposevisionlanguagemodels}
\abx@aux@cite{0}{openai2024gpt4technicalreport}
\abx@aux@segm{0}{0}{openai2024gpt4technicalreport}
\abx@aux@cite{0}{openai_o1}
\abx@aux@segm{0}{0}{openai_o1}
\abx@aux@cite{0}{geminiteam2024geminifamilyhighlycapable}
\abx@aux@segm{0}{0}{geminiteam2024geminifamilyhighlycapable}
\abx@aux@cite{0}{liu2023visualinstructiontuning}
\abx@aux@segm{0}{0}{liu2023visualinstructiontuning}
\abx@aux@cite{0}{Qwen2VL}
\abx@aux@segm{0}{0}{Qwen2VL}
\abx@aux@cite{0}{vlm_leaderboard}
\abx@aux@segm{0}{0}{vlm_leaderboard}
\abx@aux@cite{0}{anderson2020simtorealtransfervisionandlanguagenavigation}
\abx@aux@segm{0}{0}{anderson2020simtorealtransfervisionandlanguagenavigation}
\abx@aux@cite{0}{Hong_2022_CVPR}
\abx@aux@segm{0}{0}{Hong_2022_CVPR}
\abx@aux@cite{0}{krantz2020navgraphvisionandlanguagenavigationcontinuous}
\abx@aux@segm{0}{0}{krantz2020navgraphvisionandlanguagenavigationcontinuous}
\abx@aux@cite{0}{mattersim}
\abx@aux@segm{0}{0}{mattersim}
\abx@aux@cite{0}{habitat19iccv}
\abx@aux@segm{0}{0}{habitat19iccv}
\abx@aux@cite{0}{szot2021habitat}
\abx@aux@segm{0}{0}{szot2021habitat}
\abx@aux@cite{0}{puig2023habitat3}
\abx@aux@segm{0}{0}{puig2023habitat3}
\@writefile{toc}{\contentsline {section}{\numberline {2}Literature Review}{3}{section.1.2}\protected@file@percent }
\abx@aux@cite{0}{chen-etal-2024-mapgpt}
\abx@aux@segm{0}{0}{chen-etal-2024-mapgpt}
\abx@aux@cite{0}{pan2024langnavlanguageperceptualrepresentation}
\abx@aux@segm{0}{0}{pan2024langnavlanguageperceptualrepresentation}
\abx@aux@cite{0}{zhou2023navgptexplicitreasoningvisionandlanguage}
\abx@aux@segm{0}{0}{zhou2023navgptexplicitreasoningvisionandlanguage}
\@writefile{toc}{\contentsline {section}{\numberline {3}Methodology}{5}{section.1.3}\protected@file@percent }
\abx@aux@cite{0}{zhou2023navgptexplicitreasoningvisionandlanguage}
\abx@aux@segm{0}{0}{zhou2023navgptexplicitreasoningvisionandlanguage}
\abx@aux@cite{0}{51647}
\abx@aux@segm{0}{0}{51647}
\abx@aux@cite{0}{open-nav}
\abx@aux@segm{0}{0}{open-nav}
\abx@aux@cite{0}{navgpt2}
\abx@aux@segm{0}{0}{navgpt2}
\abx@aux@cite{0}{chen2021_HAMT}
\abx@aux@segm{0}{0}{chen2021_HAMT}
\abx@aux@cite{0}{HE2024110511_MemoryAdaptiveVLN}
\abx@aux@segm{0}{0}{HE2024110511_MemoryAdaptiveVLN}
\abx@aux@cite{0}{HE2024110511_MemoryAdaptiveVLN}
\abx@aux@segm{0}{0}{HE2024110511_MemoryAdaptiveVLN}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces The architecture of the model used in this work. The LLM is used only to create a structured list of Navigation Checkpoints that also act as sub-goals or medium-term goals for the agent to progress toward, and is useful for orienting the agent in instances where the final goal location may not be visible as well as for monitoring progress. The VLM, with its multi-modal capabilities, is used for all other tasks. Unlike prior work, with its pretrained vision and language capabilities, the VLM negates the requirement to run separate models for image captioning and reasoning tasks.}}{6}{figure.1.1}\protected@file@percent }
\newlabel{fig:fig1}{{1}{6}{The architecture of the model used in this work. The LLM is used only to create a structured list of Navigation Checkpoints that also act as sub-goals or medium-term goals for the agent to progress toward, and is useful for orienting the agent in instances where the final goal location may not be visible as well as for monitoring progress. The VLM, with its multi-modal capabilities, is used for all other tasks. Unlike prior work, with its pretrained vision and language capabilities, the VLM negates the requirement to run separate models for image captioning and reasoning tasks}{figure.1.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Problem Formulation}{6}{subsection.1.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Framework and Prompts}{6}{subsection.1.3.2}\protected@file@percent }
\abx@aux@cite{0}{rxr}
\abx@aux@segm{0}{0}{rxr}
\abx@aux@cite{0}{Matterport3D}
\abx@aux@segm{0}{0}{Matterport3D}
\abx@aux@cite{0}{Matterport3D}
\abx@aux@segm{0}{0}{Matterport3D}
\abx@aux@cite{0}{habitat19iccv}
\abx@aux@segm{0}{0}{habitat19iccv}
\abx@aux@cite{0}{szot2021habitat}
\abx@aux@segm{0}{0}{szot2021habitat}
\abx@aux@cite{0}{puig2023habitat3}
\abx@aux@segm{0}{0}{puig2023habitat3}
\abx@aux@cite{0}{mattersim}
\abx@aux@segm{0}{0}{mattersim}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Finetuning Data Generation for Continuous Environment}{8}{subsection.1.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Experiment}{9}{section.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Datasets and Environment Simulation}{9}{subsection.1.4.1}\protected@file@percent }
\abx@aux@cite{0}{Qwen-VL}
\abx@aux@segm{0}{0}{Qwen-VL}
\abx@aux@cite{0}{Qwen2VL}
\abx@aux@segm{0}{0}{Qwen2VL}
\abx@aux@cite{0}{vlm_leaderboard}
\abx@aux@segm{0}{0}{vlm_leaderboard}
\abx@aux@cite{0}{Nguyen-Mau_2024_ACCV}
\abx@aux@segm{0}{0}{Nguyen-Mau_2024_ACCV}
\abx@aux@cite{0}{LoRA}
\abx@aux@segm{0}{0}{LoRA}
\abx@aux@cite{0}{MLSYS2024_42a452cb}
\abx@aux@segm{0}{0}{MLSYS2024_42a452cb}
\abx@aux@cite{0}{zheng2024llamafactory}
\abx@aux@segm{0}{0}{zheng2024llamafactory}
\abx@aux@cite{0}{openai2024gpt4technicalreport}
\abx@aux@segm{0}{0}{openai2024gpt4technicalreport}
\abx@aux@cite{0}{open-nav}
\abx@aux@segm{0}{0}{open-nav}
\abx@aux@cite{0}{mattersim}
\abx@aux@segm{0}{0}{mattersim}
\abx@aux@cite{0}{long2023_discussnav}
\abx@aux@segm{0}{0}{long2023_discussnav}
\abx@aux@cite{0}{pan2024langnavlanguageperceptualrepresentation}
\abx@aux@segm{0}{0}{pan2024langnavlanguageperceptualrepresentation}
\abx@aux@cite{0}{lin2024navcotboostingllmbasedvisionandlanguage}
\abx@aux@segm{0}{0}{lin2024navcotboostingllmbasedvisionandlanguage}
\abx@aux@cite{0}{zhou2023navgptexplicitreasoningvisionandlanguage}
\abx@aux@segm{0}{0}{zhou2023navgptexplicitreasoningvisionandlanguage}
\abx@aux@cite{0}{open-nav}
\abx@aux@segm{0}{0}{open-nav}
\abx@aux@cite{0}{krantz2020navgraphvisionandlanguagenavigationcontinuous}
\abx@aux@segm{0}{0}{krantz2020navgraphvisionandlanguagenavigationcontinuous}
\abx@aux@cite{0}{chen2021_HAMT}
\abx@aux@segm{0}{0}{chen2021_HAMT}
\abx@aux@cite{0}{navgpt2}
\abx@aux@segm{0}{0}{navgpt2}
\abx@aux@cite{0}{hong2021_vlnbert}
\abx@aux@segm{0}{0}{hong2021_vlnbert}
\abx@aux@cite{0}{Hong_2022_CVPR}
\abx@aux@segm{0}{0}{Hong_2022_CVPR}
\abx@aux@cite{0}{chen-etal-2024-mapgpt}
\abx@aux@segm{0}{0}{chen-etal-2024-mapgpt}
\abx@aux@cite{0}{krantz2020navgraphvisionandlanguagenavigationcontinuous}
\abx@aux@segm{0}{0}{krantz2020navgraphvisionandlanguagenavigationcontinuous}
\abx@aux@cite{0}{chen-etal-2024-mapgpt}
\abx@aux@segm{0}{0}{chen-etal-2024-mapgpt}
\abx@aux@cite{0}{navgpt2}
\abx@aux@segm{0}{0}{navgpt2}
\abx@aux@cite{0}{long2023_discussnav}
\abx@aux@segm{0}{0}{long2023_discussnav}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Implementation Details}{10}{subsection.1.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Experiment Results}{10}{subsection.1.4.3}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Comparison of the model in this work against prior work in RxR dataset. Qwen2-VL-7B, as implemented in this work performs well below other models regardless of approach to multi-modality. Navigation Error as a proportion of Trajectory Length is high, suggesting that the model is not choosing to stop at the correct location. *: Results from VLN-CE task.}}{11}{table.1.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Observation taken at Steps 6 of a trajectory. The agent is hallucinating, generating text that suggests that the first image shows a kitchen sink.}}{11}{figure.1.2}\protected@file@percent }
\newlabel{fig:fig2}{{2}{11}{Observation taken at Steps 6 of a trajectory. The agent is hallucinating, generating text that suggests that the first image shows a kitchen sink}{figure.1.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Observations taken at Steps 33 and 34 of a trajectory. The agent chooses to turn 180\textdegree a total of 10 times consecutively, switching between the observations seen in Step 33 and Step 34 and appears stuck in a cycle.}}{12}{figure.1.3}\protected@file@percent }
\newlabel{fig:fig3}{{3}{12}{Observations taken at Steps 33 and 34 of a trajectory. The agent chooses to turn 180\textdegree a total of 10 times consecutively, switching between the observations seen in Step 33 and Step 34 and appears stuck in a cycle}{figure.1.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Conclusion and Future Work}{13}{section.1.5}\protected@file@percent }
\abx@aux@read@bbl@mdfivesum{D620558F589D1C34887E9BC9F6B8EE17}
\abx@aux@defaultrefcontext{0}{attenion_is_all_you_need}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{mattersim}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{pmlr-v155-anderson21a}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{krantz2020navgraphvisionandlanguagenavigationcontinuous}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{long2023_discussnav}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{pan2024langnavlanguageperceptualrepresentation}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{zhou2023navgptexplicitreasoningvisionandlanguage}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{lin2024navcotboostingllmbasedvisionandlanguage}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{open-nav}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{openai2024gpt4technicalreport}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{li2022blipbootstrappinglanguageimagepretraining}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{hong2021_vlnbert}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{navgpt2}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{chen2021_HAMT}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{HE2024110511_MemoryAdaptiveVLN}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{Qwen-VL}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{Qwen2VL}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{qwen2}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{geminiteam2024geminifamilyhighlycapable}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{LoRA}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{MLSYS2024_42a452cb}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{8954045}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{8953608}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{li2019robustnavigationlanguagepretraining}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{radford2018improving}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{touvron2023llamaopenefficientfoundation}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{li2023blip2bootstrappinglanguageimagepretraining}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{zhu2021deformabledetrdeformabletransformers}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{dosovitskiy2021imageworth16x16words}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{9156554}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{Guhur_2021_ICCV}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{devlin-etal-2019-bert}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{dai2023instructblipgeneralpurposevisionlanguagemodels}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{10203681}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{51647}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{wu2022visionlanguagenavigationsurveytaxonomy}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{9879544}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{chen-etal-2024-mapgpt}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{openai_o1}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{liu2023visualinstructiontuning}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{vlm_leaderboard}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{anderson2020simtorealtransfervisionandlanguagenavigation}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{Hong_2022_CVPR}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{habitat19iccv}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{szot2021habitat}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{puig2023habitat3}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{rxr}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{Matterport3D}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{Nguyen-Mau_2024_ACCV}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{zheng2024llamafactory}{none/global//global/global}
\gdef \@abspage@last{17}
