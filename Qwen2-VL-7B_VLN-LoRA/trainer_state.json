{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.986666666666667,
  "eval_steps": 500,
  "global_step": 336,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.08888888888888889,
      "grad_norm": 0.8348440527915955,
      "learning_rate": 2.9411764705882354e-05,
      "loss": 0.8767,
      "step": 10
    },
    {
      "epoch": 0.17777777777777778,
      "grad_norm": 0.4351803958415985,
      "learning_rate": 5.882352941176471e-05,
      "loss": 0.7159,
      "step": 20
    },
    {
      "epoch": 0.26666666666666666,
      "grad_norm": 0.6014789938926697,
      "learning_rate": 8.823529411764706e-05,
      "loss": 0.5009,
      "step": 30
    },
    {
      "epoch": 0.35555555555555557,
      "grad_norm": 0.6390024423599243,
      "learning_rate": 9.990263847374976e-05,
      "loss": 0.3342,
      "step": 40
    },
    {
      "epoch": 0.4444444444444444,
      "grad_norm": 0.3480278551578522,
      "learning_rate": 9.930902394260747e-05,
      "loss": 0.2962,
      "step": 50
    },
    {
      "epoch": 0.5333333333333333,
      "grad_norm": 0.4903218448162079,
      "learning_rate": 9.818229479678158e-05,
      "loss": 0.2461,
      "step": 60
    },
    {
      "epoch": 0.6222222222222222,
      "grad_norm": 0.4715298116207123,
      "learning_rate": 9.653463289927411e-05,
      "loss": 0.2105,
      "step": 70
    },
    {
      "epoch": 0.7111111111111111,
      "grad_norm": 0.4100508689880371,
      "learning_rate": 9.438385228425938e-05,
      "loss": 0.1769,
      "step": 80
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.708168625831604,
      "learning_rate": 9.175320655700406e-05,
      "loss": 0.174,
      "step": 90
    },
    {
      "epoch": 0.8888888888888888,
      "grad_norm": 0.6951552033424377,
      "learning_rate": 8.86711374827494e-05,
      "loss": 0.208,
      "step": 100
    },
    {
      "epoch": 0.9777777777777777,
      "grad_norm": 0.6096422076225281,
      "learning_rate": 8.517096748273951e-05,
      "loss": 0.1786,
      "step": 110
    },
    {
      "epoch": 1.0666666666666667,
      "grad_norm": 0.6489633917808533,
      "learning_rate": 8.129053936203687e-05,
      "loss": 0.1277,
      "step": 120
    },
    {
      "epoch": 1.1555555555555554,
      "grad_norm": 0.59391850233078,
      "learning_rate": 7.707180716428237e-05,
      "loss": 0.0822,
      "step": 130
    },
    {
      "epoch": 1.2444444444444445,
      "grad_norm": 0.5116313099861145,
      "learning_rate": 7.256038257695687e-05,
      "loss": 0.0823,
      "step": 140
    },
    {
      "epoch": 1.3333333333333333,
      "grad_norm": 0.6755154728889465,
      "learning_rate": 6.780504179127734e-05,
      "loss": 0.0856,
      "step": 150
    },
    {
      "epoch": 1.4222222222222223,
      "grad_norm": 0.4390513002872467,
      "learning_rate": 6.28571981484123e-05,
      "loss": 0.0961,
      "step": 160
    },
    {
      "epoch": 1.511111111111111,
      "grad_norm": 0.4938647449016571,
      "learning_rate": 5.7770346273610254e-05,
      "loss": 0.0857,
      "step": 170
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.4864846467971802,
      "learning_rate": 5.2599483708099016e-05,
      "loss": 0.0695,
      "step": 180
    },
    {
      "epoch": 1.6888888888888889,
      "grad_norm": 0.5263475775718689,
      "learning_rate": 4.740051629190099e-05,
      "loss": 0.0593,
      "step": 190
    },
    {
      "epoch": 1.7777777777777777,
      "grad_norm": 0.4905257225036621,
      "learning_rate": 4.2229653726389765e-05,
      "loss": 0.0627,
      "step": 200
    },
    {
      "epoch": 1.8666666666666667,
      "grad_norm": 0.6454986929893494,
      "learning_rate": 3.714280185158771e-05,
      "loss": 0.0839,
      "step": 210
    },
    {
      "epoch": 1.9555555555555557,
      "grad_norm": 0.6341016292572021,
      "learning_rate": 3.219495820872265e-05,
      "loss": 0.0811,
      "step": 220
    },
    {
      "epoch": 2.0444444444444443,
      "grad_norm": 0.3797047734260559,
      "learning_rate": 2.7439617423043145e-05,
      "loss": 0.0701,
      "step": 230
    },
    {
      "epoch": 2.1333333333333333,
      "grad_norm": 0.5671457648277283,
      "learning_rate": 2.2928192835717644e-05,
      "loss": 0.0427,
      "step": 240
    },
    {
      "epoch": 2.2222222222222223,
      "grad_norm": 0.4647824764251709,
      "learning_rate": 1.8709460637963123e-05,
      "loss": 0.0433,
      "step": 250
    },
    {
      "epoch": 2.311111111111111,
      "grad_norm": 0.42227110266685486,
      "learning_rate": 1.4829032517260489e-05,
      "loss": 0.0301,
      "step": 260
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.5212218761444092,
      "learning_rate": 1.132886251725061e-05,
      "loss": 0.0447,
      "step": 270
    },
    {
      "epoch": 2.488888888888889,
      "grad_norm": 0.4886891841888428,
      "learning_rate": 8.246793442995954e-06,
      "loss": 0.0361,
      "step": 280
    },
    {
      "epoch": 2.5777777777777775,
      "grad_norm": 0.5435404777526855,
      "learning_rate": 5.616147715740611e-06,
      "loss": 0.0449,
      "step": 290
    },
    {
      "epoch": 2.6666666666666665,
      "grad_norm": 0.37764206528663635,
      "learning_rate": 3.465367100725908e-06,
      "loss": 0.0376,
      "step": 300
    },
    {
      "epoch": 2.7555555555555555,
      "grad_norm": 0.6204361319541931,
      "learning_rate": 1.8177052032184283e-06,
      "loss": 0.0449,
      "step": 310
    },
    {
      "epoch": 2.8444444444444446,
      "grad_norm": 0.5925295948982239,
      "learning_rate": 6.909760573925561e-07,
      "loss": 0.035,
      "step": 320
    },
    {
      "epoch": 2.9333333333333336,
      "grad_norm": 0.6425180435180664,
      "learning_rate": 9.73615262502503e-08,
      "loss": 0.0407,
      "step": 330
    },
    {
      "epoch": 2.986666666666667,
      "step": 336,
      "total_flos": 1.4462434448852582e+17,
      "train_loss": 0.15847577527165413,
      "train_runtime": 1641.4929,
      "train_samples_per_second": 1.645,
      "train_steps_per_second": 0.205
    }
  ],
  "logging_steps": 10,
  "max_steps": 336,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.4462434448852582e+17,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
